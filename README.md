# word2vec-demo

- This is a demo of word2vec skip-gram architecture
  - The sliding window size is 3
  - We use a center word (in one hot vector format) as an input to predict context words (in one hot vector format)
  - After the training is done, the hidden layer can be used as word embeddings and we can observe that similar words will be close to each other in vector space

## Credits

- Forked from https://github.com/study-ml/word2vec-demo
- Credits for this fork: Daniel Ramos for IMAGINARY
